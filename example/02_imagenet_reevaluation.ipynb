{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation with ImageNet excluding error data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Download Imagenet dataset  \n",
    "First, please register as an ImageNet user [here](https://image-net.org/signup.php).  \n",
    "After approved, please download 2012 `validation images(all task)` in the same directory.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Expand ImageNet into a folder structure with prepro_imagenet.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sh prepare.sh"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ImageNet is extracted in the following folder.  \n",
    "\n",
    "imagenet/val/\n",
    "├── n01440764\n",
    "│   ├── ILSVRC2012_val_00000293.JPEG\n",
    "│   ├── ILSVRC2012_val_00002138.JPEG\n",
    "│   ├── ......\n",
    "├── ......"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Install Adansons Base with `pip`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/adansons/base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Create new project\n",
    "You can create new project via `base new` command.  \n",
    "Here, we will create a project named imagenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0mYour Project UID\n",
      "----------------\n",
      "b92973bc75e13337b702\n",
      "\n",
      "save Project UID in local file (~/.base/projects)\n",
      "\u001b[0m\u001b[0m"
     ]
    }
   ],
   "source": [
    "!base new imagenet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Import data files\n",
    "Next, add ImageNet to the `imagenet` project.  \n",
    "\n",
    "You have to specify your dataset directory and file extension via `--directory` and `--extension` option.  \n",
    "Also, you need to specify the parsing rule via `--parse` option; it automatically parses and links dataset information in the path name according to given parsing rule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0mCheck datafiles...\n",
      "\u001b[0mfound 50000 files with JPEG extension.\n",
      "50000/50000 files uploaded.                        \u001b[0m[0m\n",
      "\u001b[0mSuccess!\n",
      "\u001b[0m\u001b[0m"
     ]
    }
   ],
   "source": [
    "# This could take time depending on the the data amount\n",
    "# It could take around 3 mins on the MNIST dataset size (= 50000 files)\n",
    "!base import imagenet --directory imagenet --extension JPEG --parse \"{dataType}/{label}/{id}.JPEG\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Import external metadata files\n",
    "Import `error_data.csv`, which is the aggregate of ImagenNet error data.  \n",
    "If you get an error message `Failed to join the table`, this processing continues intenally. (It takes about 5 minutes)  \n",
    "So, you should run `project.attrs` to check that the processing have finished."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 tables found! (errordata.csv)\n",
      "\n",
      "1 table joining rule was estimated!\n",
      "\n",
      "Below table joining rule will be applied...\n",
      "\n",
      "\n",
      "Rule no.1\n",
      "\n",
      "\tkey 'id'\t->\tconnected to 'id' key on exist table\n",
      "\tkey 'originalLabel'\t->\tnewly added\n",
      "\tkey 'correction'\t->\tnewly added\n",
      "\n",
      "1 tables will be applied\n",
      "Table 1 sample record:\n",
      "\t{'id': 'ILSVRC2012_val_00023277', 'originalLabel': 582, 'correction': '930,963,868,923,813,415'}\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Failed to join the tables",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/ssuzuki/dev/ImageNet/02_imagenet_reevaluation.ipynb Cell 13'\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bssuzuki/home/ssuzuki/dev/ImageNet/02_imagenet_reevaluation.ipynb#ch0000012vscode-remote?line=5'>6</a>\u001b[0m join_rule \u001b[39m=\u001b[39m {\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bssuzuki/home/ssuzuki/dev/ImageNet/02_imagenet_reevaluation.ipynb#ch0000012vscode-remote?line=6'>7</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mid\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mid\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bssuzuki/home/ssuzuki/dev/ImageNet/02_imagenet_reevaluation.ipynb#ch0000012vscode-remote?line=7'>8</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39moriginalLabel\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bssuzuki/home/ssuzuki/dev/ImageNet/02_imagenet_reevaluation.ipynb#ch0000012vscode-remote?line=8'>9</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mcorrection\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bssuzuki/home/ssuzuki/dev/ImageNet/02_imagenet_reevaluation.ipynb#ch0000012vscode-remote?line=9'>10</a>\u001b[0m }\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bssuzuki/home/ssuzuki/dev/ImageNet/02_imagenet_reevaluation.ipynb#ch0000012vscode-remote?line=10'>11</a>\u001b[0m \u001b[39m# add metafile\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bssuzuki/home/ssuzuki/dev/ImageNet/02_imagenet_reevaluation.ipynb#ch0000012vscode-remote?line=11'>12</a>\u001b[0m project\u001b[39m.\u001b[39;49madd_metafile(\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bssuzuki/home/ssuzuki/dev/ImageNet/02_imagenet_reevaluation.ipynb#ch0000012vscode-remote?line=12'>13</a>\u001b[0m     file_path\u001b[39m=\u001b[39;49m[\u001b[39m\"\u001b[39;49m\u001b[39merrordata.csv\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bssuzuki/home/ssuzuki/dev/ImageNet/02_imagenet_reevaluation.ipynb#ch0000012vscode-remote?line=13'>14</a>\u001b[0m     join_rule\u001b[39m=\u001b[39;49mjoin_rule,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bssuzuki/home/ssuzuki/dev/ImageNet/02_imagenet_reevaluation.ipynb#ch0000012vscode-remote?line=14'>15</a>\u001b[0m     auto\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bssuzuki/home/ssuzuki/dev/ImageNet/02_imagenet_reevaluation.ipynb#ch0000012vscode-remote?line=15'>16</a>\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/ImageNet/lib/python3.9/site-packages/base/project.py:723\u001b[0m, in \u001b[0;36mProject.add_metafile\u001b[0;34m(self, file_path, attributes, join_rule, auto, join_rule_path, verbose)\u001b[0m\n\u001b[1;32m    717\u001b[0m             res \u001b[39m=\u001b[39m requests\u001b[39m.\u001b[39mput(\n\u001b[1;32m    718\u001b[0m                 url,\n\u001b[1;32m    719\u001b[0m                 json\u001b[39m.\u001b[39mdumps(payload, ensure_ascii\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\u001b[39m.\u001b[39mencode(\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m    720\u001b[0m                 headers\u001b[39m=\u001b[39mHEADER,\n\u001b[1;32m    721\u001b[0m             )\n\u001b[1;32m    722\u001b[0m             \u001b[39mif\u001b[39;00m res\u001b[39m.\u001b[39mstatus_code \u001b[39m!=\u001b[39m \u001b[39m200\u001b[39m:\n\u001b[0;32m--> 723\u001b[0m                 \u001b[39mraise\u001b[39;00m \u001b[39mException\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mFailed to join the tables\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    724\u001b[0m \u001b[39melif\u001b[39;00m approved \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mm\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m (\u001b[39mnot\u001b[39;00m join_rule_path):\n\u001b[1;32m    725\u001b[0m     join_rules_info \u001b[39m=\u001b[39m {\n\u001b[1;32m    726\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mRequestedTime\u001b[39m\u001b[39m\"\u001b[39m: time\u001b[39m.\u001b[39mtime(),\n\u001b[1;32m    727\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mProjectName\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mproject_name,\n\u001b[1;32m    728\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mBody\u001b[39m\u001b[39m\"\u001b[39m: {},\n\u001b[1;32m    729\u001b[0m     }\n",
      "\u001b[0;31mException\u001b[0m: Failed to join the tables"
     ]
    }
   ],
   "source": [
    "from base import Project\n",
    "project = Project('imagenet')\n",
    "\n",
    "# Specify join rules with project tables like `{\"New table key\": \"Exist table key\"}\n",
    "# if you have new key, replace \"Exist table key\" with None\n",
    "join_rule = {\n",
    "    \"id\": \"id\",\n",
    "    \"originalLabel\": None,\n",
    "    \"correction\": None\n",
    "}\n",
    "# add metafile\n",
    "project.add_metafile(\n",
    "    file_path=[\"error_data.csv\"],\n",
    "    join_rule=join_rule,\n",
    "    auto=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': {'LowerValue': 'ILSVRC2012_val_00000001',\n",
       "  'UpperValue': 'ILSVRC2012_val_00050000',\n",
       "  'ValueType': 'str',\n",
       "  'RecordedCount': 49971},\n",
       " 'correction': {'LowerValue': '0',\n",
       "  'UpperValue': '-1',\n",
       "  'ValueType': 'str',\n",
       "  'RecordedCount': 14256},\n",
       " 'label': {'LowerValue': 'n01440764',\n",
       "  'UpperValue': 'n15075141',\n",
       "  'ValueType': 'str',\n",
       "  'RecordedCount': 49971},\n",
       " 'dataType': {'LowerValue': 'val',\n",
       "  'UpperValue': 'val',\n",
       "  'ValueType': 'str',\n",
       "  'RecordedCount': 49971},\n",
       " 'originalLabel': {'LowerValue': '0',\n",
       "  'UpperValue': '999',\n",
       "  'ValueType': 'int',\n",
       "  'RecordedCount': 14256}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check to see if the tables have been joined\n",
    "project = Project('imagenet')\n",
    "project.attrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Define Dataset class & preprocess function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch torchvision pillow tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from base import Project, Dataset\n",
    "from base.files import Files\n",
    "\n",
    "import torch\n",
    "import torch.nn.parallel\n",
    "import torch.optim\n",
    "import torch.utils.data\n",
    "import torch.utils.data.distributed\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from typing import Callable, Optional, Tuple\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset excluding error data\n",
    "class ImageNetDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        files: Files,\n",
    "        target_key: str,\n",
    "        model_name: str,\n",
    "        transform: Optional[Callable] = None,\n",
    "    ) -> None:\n",
    "\n",
    "        super().__init__(files, target_key, transform)\n",
    "        self.external_filter()\n",
    "        self.y = sorted(set([getattr(i, self.target_key) for i in files]))\n",
    "        self.convert_dict = {i: j for j, i in enumerate(self.y)}\n",
    "        self.model_name = model_name\n",
    "\n",
    "    def __getitem__(self, idx: int) -> Tuple:\n",
    "        path = self.files_path[idx][1]\n",
    "        data = self.transform(path, self.model_name)\n",
    "        label = self.files_path[idx][0].get(self.target_key)\n",
    "        label = self.convert_dict[label]\n",
    "        return data, label\n",
    "    \n",
    "    def external_filter(self):\n",
    "        self.files_path = [[record, path] for record, path in zip(self.files.items, self.paths) if not record.get('correction', False)]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.files_path)\n",
    "\n",
    "\n",
    "# Functions for image preprocessing\n",
    "def preprocess_image(image_path, model_name):\n",
    "    normalize = transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "    # convert gray to rgb if needed\n",
    "    image = Image.open(image_path)\n",
    "    if image.mode != \"RGB\":\n",
    "        image = image.convert(\"RGB\")\n",
    "\n",
    "    sizes = {\n",
    "        \"convnext_large\": (232, 224),\n",
    "        \"efficientnet_b7\": (633, 600),\n",
    "        \"convnext_base\": (232, 224),\n",
    "        \"convnext_small\": (230, 224),\n",
    "        \"efficientnet_b5\": (489, 456),\n",
    "        \"vit_b_16\": (256, 224),\n",
    "        \"regnet_x_32gf\": (256, 224),\n",
    "        \"efficientnet_b3\": (320, 300),\n",
    "        \"convnext_tiny\": (236, 224),\n",
    "        \"efficientnet_b4\": (384, 380),\n",
    "    }\n",
    "    # last two letters of model_name\n",
    "    if \"efficientnet\" in model_name:\n",
    "        interpolation = transforms.InterpolationMode.BICUBIC\n",
    "    else:\n",
    "        interpolation = transforms.InterpolationMode.BILINEAR\n",
    "    resize_size = sizes[model_name][0]\n",
    "    crop_size = sizes[model_name][1]\n",
    "    image = transforms.Resize(resize_size, interpolation=interpolation)(image)\n",
    "    image = transforms.CenterCrop(crop_size)(image)\n",
    "    image = transforms.ToTensor()(image)\n",
    "    image = normalize(image)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(model_funcs, val_loader):\n",
    "    res = {}\n",
    "    for model_name, model_func in model_funcs.items():\n",
    "        model = model_func(pretrained=True)\n",
    "        model.eval()\n",
    "        model.to(\"cuda\")\n",
    "        accs = {}\n",
    "        bar = tqdm(total=len(val_loader))\n",
    "        bar.set_description(f\"Evaluating {model_name}...\")\n",
    "        i = 0\n",
    "        with torch.no_grad():\n",
    "            for i, (images, target) in enumerate(val_loader):\n",
    "                output = model(images.to(\"cuda\"))\n",
    "                acc = accuracy(output, target.to(\"cuda\"))\n",
    "                for k, v in acc.items():\n",
    "                    if k not in accs:\n",
    "                        accs[k] = torch.tensor([]).to(\"cuda\")\n",
    "                    accs[k] = torch.cat((accs[k], v))\n",
    "                bar.update(1)\n",
    "\n",
    "        for k, v in accs.items():\n",
    "            print(f\"{model_name} top{k} accuracy: {v.mean().item():.2f}%\")\n",
    "            res[model_name + \"-\" + str(k)] = {\"history\": v, \"mean\": v.mean()}\n",
    "\n",
    "    return res\n",
    "\n",
    "def accuracy(output, target, topk=(1, 5)):\n",
    "\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        _, pred = output.topk(\n",
    "            maxk, 1, True, True\n",
    "        )  # pred : indices. topk : get topk tensors along dim = 1 (within 1000 classes)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        topk_accs = {}\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
    "            topk_accs[k] = correct_k.mul_(100 / batch_size)\n",
    "\n",
    "        return topk_accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating convnext_large...: 100%|█████████▉| 1116/1117 [03:56<00:00,  4.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convnext_large top1 accuracy: 95.57%\n",
      "convnext_large top5 accuracy: 99.30%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating convnext_large...: 100%|██████████| 1117/1117 [03:56<00:00,  4.71it/s]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "model_funcs = {\n",
    "    \"convnext_large\": models.convnext_large,\n",
    "    # \"efficientnet_b7\": models.efficientnet_b7,\n",
    "    # \"convnext_base\": models.convnext_base,\n",
    "    # \"convnext_small\": models.convnext_small,\n",
    "    # \"efficientnet_b5\": models.efficientnet_b5,\n",
    "    # \"vit_b_16\": models.vit_b_16,\n",
    "    # \"regnet_x_32gf\": models.regnet_x_32gf,\n",
    "    # \"efficientnet_b3\": models.efficientnet_b3,\n",
    "    # \"convnext_tiny\": models.convnext_tiny,\n",
    "    # \"efficientnet_b4\": models.efficientnet_b4,\n",
    "}\n",
    "\n",
    "# change val_files to your own experiment\n",
    "val_files = Project(\"imagenet\").files(query=[\"correction is not None\"])\n",
    "# in order to get the correct label, you need to use the all files\n",
    "all_files = Project(\"imagenet\").files()\n",
    "\n",
    "# Start evaluation\n",
    "res_py = {}\n",
    "for model_name, model_func in model_funcs.items():\n",
    "    val_dataset = ImageNetDataset(\n",
    "        files=all_files,\n",
    "        target_key=\"label\",\n",
    "        transform=preprocess_image,\n",
    "        model_name=model_name,\n",
    "    )\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset, batch_size=batch_size\n",
    "    )\n",
    "\n",
    "    res = eval({model_name: model_func}, val_loader)\n",
    "    # cast data to python list\n",
    "    for k, v in res.items():\n",
    "        res_py[k] = {\"mean\": v[\"mean\"].item()}\n",
    "\n",
    "# Save evaluation result\n",
    "with open(\"imagenet_acc.json\", \"w\") as f:\n",
    "        json.dump(res_py, f)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 ('.venv': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "29382744e94eef6532ebbbac5266f100004e3d3a86bc2ae618043ee14225c8e6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
